{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b84304-9d9d-4de3-b046-72d169aab036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.10/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/miniforge3/envs/tf212_py310/lib/python3.10/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c778a362-e8f9-4f59-b4d8-5a45d62bfff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SKTBrain/KoBERT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d964b1-75c9-48a2-9d3b-72ddb5e5447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1548f4-da3c-47aa-b55f-35154782d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454410a2-4d3e-4d2f-8929-22819f7621c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AdamW, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba11aab3-251b-484f-b3f1-ba5c60174bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv 파일을 읽어오기\n",
    "data = pd.read_csv(\"restaurant_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad9a2f0f-9f3c-46df-be1f-37d35f7a8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_only = data[[\"발화문\", \"인텐트\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7339d5ef-0111-4e07-a954-e17280c20337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "\n",
    "# 데이터 임베딩\n",
    "embedding = tokenizer(data_only['발화문'].tolist(), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6a9326a-bdd3-481e-ac15-50cf7d1b5b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45693/260234296.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_only['인텐트'] = le.fit_transform(data_only['인텐트'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_only['인텐트'] = le.fit_transform(data_only['인텐트'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca404919-7119-450d-bdb7-48201c72e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = embedding['input_ids']\n",
    "attention_masks = embedding['attention_mask']\n",
    "labels = data_only['인텐트'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b2cad8-d4b9-4291-bdcf-c0467659c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MenuDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = [torch.tensor(ids, dtype=torch.long) for ids in input_ids]\n",
    "        self.attention_masks = [torch.tensor(mask, dtype=torch.long) for mask in attention_masks]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f347932-5a07-4db6-bfa7-555e2ab1d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = MenuDataset(input_ids=input_ids, attention_masks=attention_masks, labels=labels)\n",
    "\n",
    "# 데이터셋을 학습용과 검증용으로 분리\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cec05e88-210d-4881-aa54-39019d4d7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parmeter\n",
    "epochs= 5\n",
    "batch_size=32\n",
    "lr = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5320cac-0fe4-4799-8ec1-cd3885024f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "284b54d8-b006-4d0e-be41-f56d114c19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(ElectraClassifier, self).__init__()\n",
    "        self.electra = AutoModelForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28162bec-ae5e-427f-ad90-3d5e740e97e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7260/7260 [09:48<00:00, 12.34it/s]\n",
      "Validating: 100%|██████████| 1815/1815 [00:45<00:00, 40.27it/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.6038 Accuracy: 0.5820 F1-score: 0.5508 Precision: 0.5466 Recall: 0.5820\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7260/7260 [09:48<00:00, 12.34it/s]\n",
      "Validating: 100%|██████████| 1815/1815 [00:45<00:00, 40.22it/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4931 Accuracy: 0.6058 F1-score: 0.5842 Precision: 0.5920 Recall: 0.6058\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7260/7260 [09:47<00:00, 12.35it/s]\n",
      "Validating: 100%|██████████| 1815/1815 [00:45<00:00, 40.26it/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4560 Accuracy: 0.6144 F1-score: 0.5963 Precision: 0.6063 Recall: 0.6144\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7260/7260 [09:48<00:00, 12.34it/s]\n",
      "Validating: 100%|██████████| 1815/1815 [00:45<00:00, 40.19it/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4255 Accuracy: 0.6226 F1-score: 0.6084 Precision: 0.6206 Recall: 0.6226\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7260/7260 [09:48<00:00, 12.34it/s]\n",
      "Validating: 100%|██████████| 1815/1815 [00:45<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4359 Accuracy: 0.6247 F1-score: 0.6137 Precision: 0.6238 Recall: 0.6247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "num_labels = len(np.unique(data_only['인텐트']))\n",
    "model = ElectraClassifier(num_labels)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "# 옵티마이저와 손실 함수 설정\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# 학습 및 검증\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    model.train()\n",
    "    for batch in tqdm(train_data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 검증 데이터 평가\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_predictions = []\n",
    "    val_truths = []\n",
    "    \n",
    "    for batch in tqdm(val_data_loader, desc=\"Validating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "    \n",
    "        val_losses.append(val_loss.item())\n",
    "        val_predictions.extend(torch.argmax(outputs, dim=1).cpu().detach().numpy().tolist())\n",
    "        val_truths.extend(labels.cpu().detach().numpy().tolist())\n",
    "    \n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_acc = accuracy_score(val_truths, val_predictions)\n",
    "    val_f1 = f1_score(val_truths, val_predictions, average='weighted')\n",
    "    val_precision = precision_score(val_truths, val_predictions, average='weighted')\n",
    "    val_recall = recall_score(val_truths, val_predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss:.4f} Accuracy: {val_acc:.4f} F1-score: {val_f1:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa8d4ecd-170a-450e-b981-ac032a23e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text, model, tokenizer):\n",
    "    # 텍스트를 토크나이즈하고 BERT 입력 형식에 맞게 변환\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "    \n",
    "    # 각 텐서를 GPU로 이동\n",
    "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
    "    \n",
    "    # 모델의 예측 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 가장 높은 확률을 가진 클래스의 인덱스를 가져옴\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    \n",
    "    # 예측된 인덱스를 의도로 변환\n",
    "    # 이 부분은 실제 의도와 인덱스를 매핑하는 방법에 따라 다르게 작성해야 합니다.\n",
    "    intent = le.inverse_transform([predicted.item()])[0]\n",
    "    \n",
    "    return intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64186df8-f0a0-4742-8594-5b6d1a556071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 탕수육 대자는 몇인분인가요?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제품_정보_질문\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "text = input()\n",
    "predicted_intent = predict_intent(text, model, tokenizer)\n",
    "print(predicted_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69fc8049-1ed7-4d5f-a477-7c4825d828ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /home/ubuntu/Project/HG/saved_model4 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 모델의 state_dict 저장\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/Project/HG/saved_model4/Bert_model4.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /home/ubuntu/Project/HG/saved_model4 does not exist."
     ]
    }
   ],
   "source": [
    "# 모델의 state_dict 저장\n",
    "torch.save(model.state_dict(), \"/home/ubuntu/Project/HG/saved_model4/Bert_model4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc48614-fdcf-4f9e-95f4-12d5566f5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# LabelEncoder 저장\n",
    "with open(\"/home/ubuntu/Project/HG/saved_model4/label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c655f-79c2-4908-b91e-f57af470a651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d27157-2acb-475d-9f96-f425150a7fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7730f-dd80-44a9-b9a4-9a6acd222018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e41330-8f48-44e5-8676-09dd4f6e0697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4c87c-e061-4bb6-b73e-cbe7b0a84e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842c3d0-d773-4685-8da6-5fd303166298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349111e9-01c3-44a0-ad32-26cb55ffdf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223c126-724e-4bba-929d-f760335efaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97a616-89cd-4742-b49b-dd22a59f1bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg",
   "language": "python",
   "name": "hg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
