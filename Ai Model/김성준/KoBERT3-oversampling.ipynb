{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1yK7mDzYtKw3vz86ziOaXF03F1LagQXUA","authorship_tag":"ABX9TyM1i3+FDi9nbxkd905Rk9xZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/project/Data4.xlsx', engine='openpyxl')"],"metadata":{"id":"KmS6rSZwTjEg","executionInfo":{"status":"ok","timestamp":1700446945874,"user_tz":-540,"elapsed":4011,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from transformers import BertTokenizer\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import numpy as np\n","from tqdm import tqdm"],"metadata":{"id":"mZnNhYrXT6Dv","executionInfo":{"status":"ok","timestamp":1700446960150,"user_tz":-540,"elapsed":12678,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data['label_idx'] = data['label_idx'].apply(lambda x: list(map(int, x.split(','))))"],"metadata":{"id":"tOcUiSidUSTk","executionInfo":{"status":"ok","timestamp":1700446962091,"user_tz":-540,"elapsed":542,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["mlb = MultiLabelBinarizer()\n","data_labels = mlb.fit_transform(data['label_idx'])\n","\n","num_classes = len(mlb.classes_)\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')"],"metadata":{"id":"45d8slxmUV6O","executionInfo":{"status":"ok","timestamp":1700446964098,"user_tz":-540,"elapsed":862,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_sentences, test_sentences, train_labels, test_labels = train_test_split(data['SENTENCE'], data_labels, test_size=0.2)"],"metadata":{"id":"WZ0AmcozUX6V","executionInfo":{"status":"ok","timestamp":1700446965654,"user_tz":-540,"elapsed":337,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 클래스별 샘플 수 계산\n","label_counts = pd.Series(np.sum(train_labels, axis=0))\n","\n","# 가장 많은 샘플을 가진 클래스의 샘플 수\n","max_samples = label_counts.max()\n","\n","# 오버샘플링된 훈련 데이터셋 초기화\n","oversampled_sentences = []\n","oversampled_labels = []\n","\n","with tqdm(total=num_classes, desc=\"Oversampling\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","    for i in range(num_classes):\n","        # 클래스 i에 속하는 샘플 찾기\n","        class_sentences = train_sentences[train_labels[:, i] == 1]\n","        class_labels = train_labels[train_labels[:, i] == 1]\n","\n","        # 클래스에 샘플이 없으면 건너뛰기\n","        if len(class_sentences) == 0:\n","            pbar.update(1)\n","            continue\n","\n","        # 필요한 경우 샘플 복제\n","        n_samples = label_counts[i]\n","        while n_samples < max_samples:\n","            diff = min(len(class_sentences), max_samples - n_samples)\n","            oversampled_sentences.extend(class_sentences[:diff])\n","            oversampled_labels.extend(class_labels[:diff])\n","            n_samples += diff\n","\n","        # 원래 클래스 샘플 추가\n","        oversampled_sentences.extend(class_sentences)\n","        oversampled_labels.extend(class_labels)\n","        pbar.update(1)\n","\n","# 데이터셋을 섞음\n","oversampled_sentences, oversampled_labels = shuffle(oversampled_sentences, oversampled_labels)\n","\n","# 오버샘플링된 데이터셋으로 대체\n","train_sentences = oversampled_sentences\n","train_labels = np.array(oversampled_labels)\n","\n","class SentenceDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_encodings = tokenizer(list(train_sentences), truncation=True, padding=True)\n","test_encodings = tokenizer(list(test_sentences), truncation=True, padding=True)\n","\n","train_dataset = SentenceDataset(train_encodings, train_labels)\n","test_dataset = SentenceDataset(test_encodings, test_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWDmWORQTox9","outputId":"e88d7b9f-a6dd-454c-8b32-9e5fd83f9eb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Oversampling:   9%|▉          [ time left: 02:04 ]"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import torch\n","\n","class SentenceDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n"],"metadata":{"id":"-ho9kTgqUhXX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_encodings = tokenizer(list(train_sentences), truncation=True, padding=True)\n","test_encodings = tokenizer(list(test_sentences), truncation=True, padding=True)\n","\n","train_dataset = SentenceDataset(train_encodings, train_labels)\n","test_dataset = SentenceDataset(test_encodings, test_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"],"metadata":{"id":"Ni16jzYAUvld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertModel, get_linear_schedule_with_warmup\n","import torch.nn as nn\n","from transformers.optimization import AdamW\n","import numpy as np\n","\n","# KoBERT 모델 불러오기\n","bert_model = BertModel.from_pretrained('monologg/kobert')\n","\n","# CUDA 사용 가능하면 CUDA로, 아니면 CPU로 설정\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 손실 함수 및 옵티마이저 정의\n","class_weights =[]\n","total_samples = len(data)\n","label_counts = pd.Series([item for sublist in mlb.inverse_transform(data_labels) for item in sublist]).value_counts()\n","for i in range(num_classes):\n","    # 클래스 i의 샘플 수\n","    class_count = label_counts.get(i, 0)\n","\n","    # 클래스 가중치 계산: 클래스가 덜 나타날수록 더 큰 가중치를 부여\n","    if class_count > 0:\n","        weight = total_samples / (num_classes * class_count)\n","    else:\n","        weight = 0  # 클래스가 데이터셋에 전혀 나타나지 않는 경우\n","\n","    class_weights.append(weight)\n","\n","class_weights = torch.tensor(class_weights).to(device)\n","\n","\n","\n","loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n","\n","num_epochs = 5\n","\n","total_steps = len(train_loader) * num_epochs\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, bert_model, num_classes):\n","        super(CustomModel, self).__init__()\n","        self.bert_model = bert_model\n","        self.num_classes = num_classes\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert_model.config.hidden_size, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        return logits\n","\n","custom_model = CustomModel(bert_model, num_classes)\n","custom_model = custom_model.to(device)\n","\n","optimizer = AdamW(custom_model.parameters(), lr=5e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLtajUvgLFeJ","executionInfo":{"status":"ok","timestamp":1700442634932,"user_tz":-540,"elapsed":6749,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}},"outputId":"e578b230-6f33-4d4d-aa32-85aff09334d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch import nn\n","from tqdm import tqdm\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","\n","# 학습 시작\n","for epoch in range(num_epochs):\n","    # Training\n","    total_loss = 0\n","    custom_model.train()\n","    for batch in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device).float()\n","\n","        outputs = custom_model(input_ids=input_ids, attention_mask=attention_mask)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        total_loss += loss.item()\n","\n","    # Validation\n","    custom_model.eval()\n","    predictions, actuals = [], []\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device).float()\n","\n","            outputs = custom_model(input_ids=input_ids, attention_mask=attention_mask)\n","            preds = (torch.sigmoid(outputs) > 0.5).cpu().detach().numpy()\n","            predictions.extend(preds)\n","            actuals.extend(labels.cpu().detach().numpy())\n","\n","    predictions = np.array(predictions)\n","    actuals = np.array(actuals)\n","\n","    accuracy = accuracy_score(actuals.ravel(), predictions.ravel())\n","    precision = precision_score(actuals.ravel(), predictions.ravel(), average='micro')\n","    recall = recall_score(actuals.ravel(), predictions.ravel(), average='micro')\n","    f1 = f1_score(actuals.ravel(), predictions.ravel(), average='micro')\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}')\n","    print(f'Loss: {total_loss/len(train_loader):.4f}')\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'F1 Score: {f1:.4f}')\n"],"metadata":{"id":"11MYwdX2VzsN","colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"status":"error","timestamp":1700442800542,"user_tz":-540,"elapsed":151396,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}},"outputId":"ea1aee4c-fd7d-4ec8-d5c0-2e96d78f1edc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 787/787 [01:40<00:00,  7.86it/s]\n","100%|██████████| 197/197 [00:05<00:00, 33.40it/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","Loss: 0.0643\n","Accuracy: 0.9996\n","Precision: 0.9992\n","Recall: 0.9996\n","F1 Score: 0.9994\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 153/787 [00:19<01:21,  7.78it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-9c188f0cdb1c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def predict_sentence(model, tokenizer, sentence, threshold=0.3):\n","    # 모델의 디바이스 확인 (CPU 또는 CUDA)\n","    device = next(model.parameters()).device\n","\n","    # 문장 토큰화\n","    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n","    inputs = {k: v.to(device) for k, v in inputs.items() if k != 'token_type_ids'}\n","\n","    # 모델 예측\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # 활성화 함수 적용 및 임계값을 사용하여 라벨 결정\n","    predictions = torch.sigmoid(outputs).cpu().numpy() > threshold  # .cpu()를 추가하여 GPU 텐서를 CPU로 이동\n","\n","    # 예측된 라벨 인덱스 추출\n","    predicted_labels = [i for i, label in enumerate(predictions[0]) if label]\n","\n","    return predicted_labels\n","\n","# 임의의 문장을 사용하여 모델 테스트\n","for i in range(10):\n","  test_sentence = input()\n","  predicted_labels = predict_sentence(custom_model, tokenizer, test_sentence)\n","\n","  print(\"Predicted label indices:\", predicted_labels)\n","  if test_sentence == \"수고하세요\":\n","    break"],"metadata":{"id":"ZhPe8bQxWqhZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700441915232,"user_tz":-540,"elapsed":23291,"user":{"displayName":"Sjoon K","userId":"04415708541032446842"}},"outputId":"f6cf255c-c6df-4caa-ee71-e22e49a3021e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["지금 배달가능한가요?\n","Predicted label indices: [3971]\n","수고하세요\n","Predicted label indices: [1616]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vBSXcet8caLH"},"execution_count":null,"outputs":[]}]}