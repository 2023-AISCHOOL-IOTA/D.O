{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install kobert-transformers"],"metadata":{"id":"u3zW8FwaHPFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRIfCZM0IeQa","executionInfo":{"status":"ok","timestamp":1700037609851,"user_tz":-540,"elapsed":5105,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"29a701e4-8c83-4adf-fbde-f059b6328fa9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install --upgrade kobert-transformers"],"metadata":{"id":"qP2eacrDH8kd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbDUJ09bHQCo","executionInfo":{"status":"ok","timestamp":1700037218156,"user_tz":-540,"elapsed":17321,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"88f39325-3baa-435a-de52-945c1be713b0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zzTCHOisZ40n","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1700037275993,"user_tz":-540,"elapsed":1958,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"2abd7693-792f-4bfe-9935-37419d768581"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                sentence  label_idx\n","0                      네          0\n","1  네 접시 색깔은 다른데 가격은 똑같아요       1997\n","2                  네 그럼요          0\n","3           오늘 회는 뭐가 좋나요       2349\n","4          여기 배달도 하시는가요?       1750"],"text/html":["\n","  <div id=\"df-5abc5e2d-222f-450d-b8c2-85d992f2c70c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>네</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>네 접시 색깔은 다른데 가격은 똑같아요</td>\n","      <td>1997</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>네 그럼요</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>오늘 회는 뭐가 좋나요</td>\n","      <td>2349</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>여기 배달도 하시는가요?</td>\n","      <td>1750</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5abc5e2d-222f-450d-b8c2-85d992f2c70c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5abc5e2d-222f-450d-b8c2-85d992f2c70c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5abc5e2d-222f-450d-b8c2-85d992f2c70c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ecd7e3be-da30-4c8e-a22a-114ffa52c837\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecd7e3be-da30-4c8e-a22a-114ffa52c837')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ecd7e3be-da30-4c8e-a22a-114ffa52c837 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}],"source":["# 1. 필요한 데이터 가져오기\n","import pandas as pd\n","\n","data = pd.read_excel(\"/content/drive/MyDrive/젯봇/data.xlsx\", engine=\"openpyxl\")\n","\n","data.head()"]},{"cell_type":"code","source":["# 2. 데이터 분할 (train 훈련 / test 검증)\n","from sklearn.model_selection import train_test_split\n","train_data, test_data = train_test_split(data, test_size = 0.2, random_state = 42)\n","train_data.shape, test_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Ss2EDASab29","executionInfo":{"status":"ok","timestamp":1700037877948,"user_tz":-540,"elapsed":1217,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"12684aad-4713-4dbf-a0ac-5907438cb187"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((12580, 2), (3146, 2))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from kobert_transformers import get_kobert_model, get_tokenizer\n","from transformers import BertTokenizer\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertForSequenceClassification\n","\n","# tokenizer = BertTokenizer.from_pretrained('kykim/bert-kor-base')\n","# model = BertModel.from_pretrained('kykim/bert-kor-base')\n","\n","# 토크나이저, 모델 설정\n","tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n","model = BertForSequenceClassification.from_pretrained('monologg/kobert', num_labels=2998)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLXEhsXYHyVh","executionInfo":{"status":"ok","timestamp":1700038555494,"user_tz":-540,"elapsed":2141,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"f32c6b92-3e9b-4ebb-9c2d-07cdcd588a8a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# 3. 전처리 : sentence의 한국어를 숫자벡터로 변환하는 토큰화 작업\n","# Hugging face의 BERT모델 활용\n","\n","# 데이터셋 정의\n","class TextDataset(Dataset):\n","  def __init__(self, sentences, labels, tokenizer, max_len):\n","    self.sentences = sentences\n","    self.labels = labels\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","\n","  def __len__(self):\n","    return len(self.sentences)\n","\n","  def __getitem__(self, item):\n","    sentence = str(self.sentences[item])\n","    label = self.labels[item]\n","    encoding = self.tokenizer.encode_plus(\n","        sentence,\n","        add_special_tokens = True,\n","        max_length = self.max_len,\n","        return_token_type_ids = False,\n","        padding = 'max_length',\n","        truncation = True,\n","        return_attention_mask = True,\n","        return_tensors = 'pt'\n","      )\n","\n","    return {\n","        'sentence' : sentence,\n","        'input_ids' : encoding['input_ids'].flatten(),\n","        'attention_mask' : encoding['attention_mask'].flatten(),\n","        'labels' : torch.tensor(label, dtype = torch.long)\n","      }"],"metadata":{"id":"evat4UvMa2C3","executionInfo":{"status":"ok","timestamp":1700038564300,"user_tz":-540,"elapsed":483,"user":{"displayName":"정소이","userId":"03515220791152430617"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# 데이터 셋 생성\n","max_len = 128    # 최대 시퀀스 길이 설정\n","train_dataset = TextDataset(\n","    train_data['sentence'].to_numpy(),\n","    train_data['label_idx'].to_numpy(),\n","    tokenizer,\n","    max_len\n",")\n","\n","test_dataset = TextDataset(\n","    test_data['sentence'].to_numpy(),\n","    test_data['label_idx'].to_numpy(),\n","    tokenizer,\n","    max_len\n",")"],"metadata":{"id":"62B1h-Vcc6W3","executionInfo":{"status":"ok","timestamp":1700038566247,"user_tz":-540,"elapsed":3,"user":{"displayName":"정소이","userId":"03515220791152430617"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# 데이터 로더 생성\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"5L2hOkvTdS8i","executionInfo":{"status":"ok","timestamp":1700038568389,"user_tz":-540,"elapsed":1,"user":{"displayName":"정소이","userId":"03515220791152430617"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# BERT 모델 로드 및 학습 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels = len(data['label_idx'].unique()))\n","model.to(device)"],"metadata":{"id":"EJxGMQXVgv2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700038570495,"user_tz":-540,"elapsed":2,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"1526d470-0025-4bc5-dcc8-284ecbf066a7"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2998, bias=True)\n",")"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["from transformers import AdamW\n","from torch.nn import CrossEntropyLoss\n","\n","# 옵티마이저 설정\n","optimizer = torch.optim.AdamW(model.parameters(),lr=5e-5)\n","# 손실함수 설정\n","loss_fn = CrossEntropyLoss()"],"metadata":{"id":"etY_BEE5iWU9","executionInfo":{"status":"ok","timestamp":1700038572824,"user_tz":-540,"elapsed":1,"user":{"displayName":"정소이","userId":"03515220791152430617"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","import numpy as np\n","\n","# 훈련 함수\n","def train_epoch(model, data_loader, loss_fn, optimizer, device, n_examples):\n","  model = model.train()\n","  losses = []\n","  correct_predictions = 0\n","\n","  for i in tqdm(data_loader, desc=f'train epoch : {epoch + 1}'):\n","    input_ids = i[\"input_ids\"].to(device)\n","    attention_mask = i[\"attention_mask\"].to(device)\n","    labels = i[\"labels\"].to(device)\n","\n","    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","    _, preds = torch.max(outputs.logits, dim=1)\n","    loss = loss_fn(outputs.logits, labels)\n","\n","    correct_predictions += torch.sum(preds == labels)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)\n"],"metadata":{"id":"GaSIGpjyKe2x","executionInfo":{"status":"ok","timestamp":1700038574883,"user_tz":-540,"elapsed":1,"user":{"displayName":"정소이","userId":"03515220791152430617"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# 평가 함수\n","def eval_model(model, data_loader, loss_fn, device, n_examples):\n","    model = model.eval()\n","    losses = []\n","    correct_predictions = 0\n","\n","    with torch.no_grad():\n","        for i in tqdm(data_loader,  desc=f'test epoch : {epoch + 1}'):\n","            input_ids = i[\"input_ids\"].to(device)\n","            attention_mask = i[\"attention_mask\"].to(device)\n","            labels = i[\"labels\"].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs.logits, dim=1)\n","            loss = loss_fn(outputs.logits, labels)\n","\n","            correct_predictions += torch.sum(preds == labels)\n","            losses.append(loss.item())\n","\n","    return correct_predictions.double() / n_examples, np.mean(losses)\n"],"metadata":{"id":"BQ-xjGjXK_UX","executionInfo":{"status":"ok","timestamp":1700038577350,"user_tz":-540,"elapsed":1,"user":{"displayName":"정소이","userId":"03515220791152430617"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련 및 평가 루프\n","epochs = 3\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch + 1}/{epochs}')\n","    print('-' * 10)\n","\n","    train_acc, train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, len(train_dataset))\n","    print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","    val_acc, val_loss = eval_model(model, test_loader, loss_fn, device, len(test_dataset))\n","    print(f'Val loss {val_loss} accuracy {val_acc}')\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"09HgLA7ULEfV","executionInfo":{"status":"error","timestamp":1700038751084,"user_tz":-540,"elapsed":171608,"user":{"displayName":"정소이","userId":"03515220791152430617"}},"outputId":"977fe947-57e6-4f89-a2ff-59f190aa5382"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["train epoch : 1: 100%|██████████| 394/394 [01:20<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 6.061377318377422 accuracy 0.23593004769475356\n"]},{"output_type":"stream","name":"stderr","text":["train epoch : 1: 100%|██████████| 99/99 [00:07<00:00, 13.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val loss 5.799241865524138 accuracy 0.23935155753337573\n","\n","Epoch 2/3\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["train epoch : 2: 100%|██████████| 394/394 [01:20<00:00,  4.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 5.6095779135747605 accuracy 0.23950715421303656\n"]},{"output_type":"stream","name":"stderr","text":["train epoch : 2:  65%|██████▍   | 64/99 [00:04<00:02, 13.69it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-8f23505ddd2d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train loss {train_loss} accuracy {train_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Val loss {val_loss} accuracy {val_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-3456c21459e9>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, data_loader, loss_fn, device, n_examples)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# from tqdm import tqdm\n","# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","# epochs = 20\n","# for epoch in range(epochs):\n","#   # 훈련\n","#   model.train()\n","#   for batch in tqdm(train_dataloader, desc=f'Train epoch : {epoch + 1}'):\n","#     input_ids = batch['input_ids'].to(device)\n","#     attention_mask = batch['attention_mask'].to(device)\n","#     labels = batch['labels'].to(device)\n","\n","#     # 포워드 태우기\n","#     outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#     loss = outputs.loss\n","\n","#     # 백워드 태우기\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","\n","#   print(f'Epoch {epoch +1}/{epochs} completed')\n","\n","#   # 평가\n","#   model.eval()\n","#   total_loss = 0\n","#   all_preds = []\n","#   all_labels = []\n","#   with torch.no_grad():\n","#     for batch in tqdm(test_dataloader, desc=f'Test epoch : {epoch +1}'):\n","#       input_ids = batch['input_ids'].to(device)\n","#       attention_mask = batch['attention_mask'].to(device)\n","#       labels = batch['labels'].to(device)\n","\n","#       outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#       loss = outputs.loss\n","#       total_loss += loss.item()\n","\n","#       # 예측\n","#       _, preds = torch.max(outputs.logits, dim=1)\n","#       all_preds.extend(preds.tolist())\n","#       all_labels.extend(labels.tolist())\n","\n","#     avg_loss = total_loss / len(test_dataloader)\n","#     avg_accuracy = accuracy_score(all_labels, all_preds)\n","#     avg_precision = precision_score(all_labels, all_preds, average = 'weighted')\n","#     avg_recall = recall_score(all_labels, all_preds, average = 'weighted')\n","#     avg_f1 = f1_score(all_labels, all_preds, average = 'weighted')\n","\n","#     print(f'Test Loss : {avg_loss}')\n","#     print(f'Test accuracy : {avg_accuracy}')\n","#     print(f'Test f1 score : {avg_f1}')\n","#     print(f'Test precision : {avg_precision}')\n","#     print(f'Test recall : {avg_recall}')"],"metadata":{"id":"XH2MoeEui57G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"axDqEr0Mndfz"},"execution_count":null,"outputs":[]}]}