{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>후기 남길게요 오븐 스파게티 서비스로 주세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>혹시 코스요리에서 파스타만 포장 가능할까요?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentence  label_idx\n",
       "0  후기 남길게요 오븐 스파게티 서비스로 주세요          0\n",
       "1  혹시 코스요리에서 파스타만 포장 가능할까요?          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15726, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"data.xlsx\", engine=\"openpyxl\")#.iloc[:100]\n",
    "# data[\"label_idx\"] = [random.choice([0,1,2,3,4]) for _ in range(100)]\n",
    "display(data.head(2))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(all_indices))\n",
    "val_size = len(all_indices) - train_size\n",
    "train_idx, val_idx = all_indices[:int(0.8 * len(all_indices))], all_indices[int(0.8 * len(all_indices)):]\n",
    "\n",
    "num_classes = max(data[\"label_idx\"].tolist())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RangeIndex(start=0, stop=12580, step=1),\n",
       " RangeIndex(start=12580, stop=15726, step=1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# transformers 라이브러리에서 BERT 토크나이저를 임포트합니다.\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# 다국어 지원 BERT 모델을 사용하여 토크나이저 객체를 생성합니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.encodings = [\n",
    "            tokenizer.encode_plus(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512) for sentence in df[\"sentence\"].tolist()\n",
    "        ]\n",
    "        self.labels = df[\"label_idx\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # to_return = {\n",
    "        #     \"sentence_encoded\":self.encodings[idx],\n",
    "        #     \"label\":self.labels[idx]\n",
    "        # }\n",
    "        return (self.encodings[idx], self.labels[idx])\n",
    "        # return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDatasetBatch(Dataset):\n",
    "    def __init__(self, df, tokenizer, batch_size=4):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentences = df[\"sentence\"].tolist()\n",
    "        self.labels = df[\"label_idx\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # to_return = {\n",
    "        #     \"sentence_encoded\":self.encodings[idx],\n",
    "        #     \"label\":self.labels[idx]\n",
    "        # }\n",
    "        return (self.sentences[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[train_idx]\n",
    "val_data = data.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TextClassificationDataset(train_data, tokenizer)\n",
    "# val_dataset = TextClassificationDataset(val_data, tokenizer)\n",
    "train_dataset = TextClassificationDatasetBatch(train_data, tokenizer)\n",
    "val_dataset = TextClassificationDatasetBatch(val_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('후기 남길게요 오븐 스파게티 서비스로 주세요', 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('양갈비는 잘 안 나가요?',\n",
       " '국밥 굴국밥 이런거는 어떠세요?',\n",
       " '중복 할인은 안돼요',\n",
       " '미디움레어로 해주세요',\n",
       " '네 잠시만 기다리세요',\n",
       " '영수증에 대기번호도 같이 써있습니다',\n",
       " '네',\n",
       " '우리은행도 있고 현대카드도 있는데 그거는 할인 없고?',\n",
       " '이 동네 사세요?',\n",
       " '예 정식은 가격이 얼마에요?')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2806, 1101, 1443, 2236,    0,  747,    0, 1180, 2759, 1037])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_bert_tokernizer(samples):\n",
    "    # print(\"samples :: \", samples)\n",
    "    sentences, lables = [s[0] for s in samples], [s[1] for s in samples]\n",
    "    global tokenizer\n",
    "    return tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512), lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, collate_fn = collate_bert_tokernizer) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(**train_dataset[0][0])[\"pooler_output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized = tokenizer([\"이것은 문장입니다\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "# print(tokenized[\"input_ids\"].shape)\n",
    "# model(**tokenized)[\"pooler_output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer([\"이것은 문장입니다\"] * 4, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "print(tokenized[\"input_ids\"].shape)\n",
    "model(**tokenized)[\"pooler_output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  3982,  2073,  6265, 12190,     2],\n",
       "        [    0,  3982,  2073,  6265, 12190,     2],\n",
       "        [    0,  3982,  2073,  6265, 12190,     2],\n",
       "        [    0,  3982,  2073,  6265, 12190,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=tokenized[\"input_ids\"], token_type_ids=tokenized[\"token_type_ids\"], attention_mask=tokenized[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/dwook.kim/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"klue/roberta-small\")\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes, hidden_size):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = bert_model\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes) \n",
    "    \n",
    "    def forward(self, _input):\n",
    "        output = self.model(**_input)[\"pooler_output\"]\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "custom_model = CustomModel(model, num_classes, 768)\n",
    "optimizer = AdamW(custom_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dwook.kim/study/D.O/Ai Model/김동욱/231111 Bert + batch.ipynb 셀 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dwook.kim/study/D.O/Ai%20Model/%EA%B9%80%EB%8F%99%EC%9A%B1/231111%20Bert%20%2B%20batch.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mTensor(item[\u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "torch.Tensor(item[1], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/y74d9tn12ls8tx3g7nmyjc3h0000gn/T/ipykernel_7454/4120136601.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  _label = torch.tensor(F.one_hot(torch.tensor(_label, dtype=torch.long), num_classes=num_classes), dtype=torch.float).squeeze()\n",
      "/var/folders/3g/y74d9tn12ls8tx3g7nmyjc3h0000gn/T/ipykernel_7454/4120136601.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_f(F.softmax(outputs), _label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0174, -0.1574,  0.2068,  ...,  0.1841, -0.0257,  0.2325],\n",
      "        [-0.0897, -0.1325,  0.1657,  ...,  0.0426, -0.0107,  0.0971],\n",
      "        [-0.0063, -0.1700,  0.0681,  ...,  0.0938, -0.0737,  0.1298],\n",
      "        ...,\n",
      "        [-0.0067, -0.1154,  0.1552,  ...,  0.1138, -0.0716,  0.1311],\n",
      "        [-0.0688, -0.1137,  0.1341,  ...,  0.0941, -0.0464,  0.1196],\n",
      "        [-0.1594, -0.0395,  0.0297,  ...,  0.0951, -0.0749,  0.0596]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Epoch 2/2\n",
      "----------\n",
      "tensor([[ 0.3736, -0.0962,  0.2207,  ...,  0.1817, -0.0201,  0.2081],\n",
      "        [ 0.4112, -0.1317,  0.2172,  ...,  0.1246, -0.0584,  0.2213],\n",
      "        [ 0.3402, -0.2247,  0.2087,  ...,  0.1722, -0.0382,  0.1058],\n",
      "        ...,\n",
      "        [ 0.3244, -0.1503,  0.1475,  ...,  0.1443, -0.1613,  0.1717],\n",
      "        [ 0.3556, -0.1773,  0.1659,  ...,  0.1727, -0.0050,  0.2692],\n",
      "        [ 0.4056, -0.0415,  0.2137,  ...,  0.1232, -0.2285,  0.0653]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print('-' * 10)\n",
    "    # 모델을 학습 모드로 설정합니다.\n",
    "    model.train()\n",
    "    for i, (_input, _label) in enumerate(train_dataloader):\n",
    "        _label = torch.tensor(F.one_hot(torch.tensor(_label, dtype=torch.long), num_classes=num_classes), dtype=torch.float).squeeze()\n",
    "        \n",
    "        outputs = custom_model(_input)\n",
    "        loss = loss_f(F.softmax(outputs), _label)\n",
    "        loss.backward() # 역전파를 수행합니다.\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        break\n",
    "    print(outputs)\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    # for i, (_input, _label) in enumerate(val_loader):\n",
    "    #     _input = {k:v.squeeze(0) for k, v in _input.items()}\n",
    "    #     _label = torch.tensor(F.one_hot(_label, num_classes=num_classes), dtype=torch.float).squeeze()\n",
    "        \n",
    "    #     outputs = custom_model(_input)\n",
    "    #     #loss = loss_f(F.softmax(outputs), _label)\n",
    "    #     all_predictions.append( torch.argmax(F.softmax(outputs)).item() )\n",
    "    #     all_labels.append( torch.argmax(F.softmax(_label)).item() )\n",
    "        \n",
    "\n",
    "\n",
    "    # print(accuracy_score(all_labels, all_predictions))\n",
    "    # print(f1_score(all_labels, all_predictions, average=\"weighted\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3736, -0.0962,  0.2207,  ...,  0.1817, -0.0201,  0.2081],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4112, -0.1317,  0.2172,  ...,  0.1246, -0.0584,  0.2213],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
